---
layout: post
title:  "ElasticSearch笔记-Lucene概念介绍"
date:   2019-10-23 11:30 +0800
categories: es
typora-root-url: ./image
---

## Lucene词汇表和架构

Lucene诞生的目标是提供一个全文检索的功能库。基本概念：

- **文档(document)**：索引和搜索时使用的主要数据载体，包含一个或多个存有数据的字段。

- **字段(field)**：文档的一部分，包含名称和值两部分。

- **词(term)**：一个搜索单元，表示文本中的一个词。

- **标记(token)**：表示在字段文本中出现的词，由这个词的文本、开始和结束偏移量以及类型组成。

Lucene将所有信息写到**倒排索引(inverted index)**的结构中，倒排建立词与文档之间的映射。简单举个栗子，现有三个需要被索引的字段："小明 足球"、"小红 足球"、"小光 羽毛球"，简化版的索引可以看成表中所示，执行非常高效快速的搜索。

|  词   |  计数    |  文档    |
| ---- | ---- | ---- |
| 小明 |   1   |  <1>    |
| 小红 |   1   | <2> |
| 小光 |   1   | <3> |
| 足球 |   2   | <1>,<2> |
| 羽毛球 |   1   | <3> |

每个索引分为多个"写一次读多次"的**段(segment)**，建立索引时一个段写入磁盘就不能再更新，因此，被删除文档信息存在一个单独文件中，该段自身不被更新。多个段可以通过**段合并(segment merge)**合并在一起，小段合并成大段，合并需要I/O，不在需要的信息将被删除(例如被删除的文档)。检索大段比小段快，因为通过小段寻找和合并结果，比直接一个大段提供结果慢的多。

## 输入数据分析

数据转化成**倒排索引**，查询文本变成可被搜索的**词**，这个数据转化过程被称为**分析**。比如，car和cars在索引中被视为同一个，一些 字段用空格划分。**分析**的工作由**分析器**完成，由一个**分词器(tokenizer)**、0或多个**标记过滤器(token filter)**组成，也可以有0或多个字**符映射器(character mapping)**。

Lucene中的**分词器**把文本分割成多个**标记**，基本就是**词**加上一些额外信息，比如该**词**在原始文本中的位置和长度。**分词器**的处理结果称为**标记流(token stream)**，它是一个接一个的标记， 准备被过滤器处理。

除了**分词器**，Lucene分析器包含零个或多个**标记过滤器**，用来处理标记流中的**标记**。下面是 一些过滤器的例子。

- 小写过滤器(lowercase filter)：把所有的标记变成小写。
- 同义词过滤器(synonyms filter)：基于基本的同义词规则，把一个标记换成另一个同义的标记。
- 多语言词干提取过滤器(multiple language stemming filter)：减少标记(实际上是标记中的文本部分)，得到词根或者基本形式，即词干。

过滤器是一个接一个处理的。所以我们通过使用多个过滤器，几乎可以达到无限的分析可能性。

最后，字符映射器对未经分析的文本起作用，它们在分词器之前工作。因此，我们可以很容 易地从文本的整体部分去除HTML标签而无需担心它们被标记。

### 索引和查询

建立索引时，Lucene会使用你选择的**分析器**来处理你的**文档**内容。当然，不同的字段可以使用不同的**分析器**，所以**文档**的名称字段可以和汇总字段做不同的分析。如果我们愿意，也可以不分析字段。

查询时，查询将被分析。但是，你也可以选择不分析。记住这一点很关键。有时你可能希望查询一个未经分析的字段，而有时你则希望有全文搜索的分析。如果我们查询LightRed这个词，标准分析器分析这个查询后，会去查询light和red；如果我们使用不经分析的查询类型，则会明确地查询LightRed 这个词。

索引应该和查询词匹配。如果它们不匹配，Lucene 不会返回所需文档。比如，你在建立索引时使用了词干提取和小写，那你应该保证查询中的词也必须是词干和小写，否则你的查询不会返回任何结果。重要的是在索引和查询分析时，对所用标记过滤器保持相同的顺序，这样被分析出来的词是一样的。

